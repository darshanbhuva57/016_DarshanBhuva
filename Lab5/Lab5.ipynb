{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4165,
     "status": "ok",
     "timestamp": 1596557302344,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "v0BtAX1--7l_"
   },
   "outputs": [],
   "source": [
    "# Import Numpy & PyTorch\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "34f006aa7eb4bbc683c39b7059021da900180908",
    "colab_type": "text",
    "id": "tUurNfvF-7mc"
   },
   "source": [
    "A tensor is a number, vector, matrix or any n-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0b65b6bb4d15127b1d51f09abf616cfd29fa48b4",
    "colab_type": "text",
    "id": "DAOgSWEp-7oF"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1beecda01bc332596edd193cade30006e3f6cbf",
    "colab_type": "text",
    "id": "-Fi1M6pd-7oJ"
   },
   "source": [
    "We'll create a model that predicts crop yeilds for apples (*target variable*) by looking at the average temperature, rainfall and humidity (*input variables or features*) in different regions. \n",
    "\n",
    "Here's the training data:\n",
    "\n",
    ">Temp | Rain | Humidity | Prediction\n",
    ">--- | --- | --- | ---\n",
    "> 73 | 67 | 43 | 56\n",
    "> 91 | 88 | 64 | 81\n",
    "> 87 | 134 | 58 | 119\n",
    "> 102 | 43 | 37 | 22\n",
    "> 69 | 96 | 70 | 103\n",
    "\n",
    "In a **linear regression** model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
    "\n",
    "```\n",
    "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "```\n",
    "\n",
    "It means that the yield of apples is a linear or planar function of the temperature, rainfall & humidity.\n",
    "\n",
    "\n",
    "\n",
    "**Our objective**: Find a suitable set of *weights* and *biases* using the training data, to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c24b8195c0e9c6e8e13e169d264484f1f9b3b1ae",
    "colab_type": "text",
    "id": "h0dmV2Fc-7oL"
   },
   "source": [
    "## Training Data\n",
    "The training data can be represented using 2 matrices (inputs and targets), each with one row per observation and one column for variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "dfda99005fc6daf3a49ae1cdd427ccac0aa446b1",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4147,
     "status": "ok",
     "timestamp": 1596557302348,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "MaIf33bV-7oN"
   },
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bf56faf74f7e29c9ed7523308718a9ab1acc0667",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4134,
     "status": "ok",
     "timestamp": 1596557302352,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "1tnPriBD-7oa"
   },
   "outputs": [],
   "source": [
    "# Target (apples)\n",
    "targets = np.array([[56], \n",
    "                    [81], \n",
    "                    [119], \n",
    "                    [22], \n",
    "                    [103]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "70d48f83ae4fce7aba7dd78fd58dddc77c598bfd",
    "colab_type": "text",
    "id": "MyJm3YtE-7oo"
   },
   "source": [
    "Before we build a model, we need to convert inputs and targets to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "931c1bad8788e607fa100d4338e1b1fe120e2339",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4106,
     "status": "ok",
     "timestamp": 1596557302357,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "KZyKnyCc-7oq"
   },
   "outputs": [],
   "source": [
    "# Convert inputs and targets to tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "652647cd90bd0784ec4dc53472410f7358ee18c9",
    "colab_type": "text",
    "id": "y0RLCJnb-7o4"
   },
   "source": [
    "## Linear Regression Model (from scratch)\n",
    "\n",
    "The *weights* and *biases* can also be represented as matrices, initialized with random values. The first row of `w` and the first element of `b` are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6f788ae559355b3f01667be1554a5d2bdcade8db",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4083,
     "status": "ok",
     "timestamp": 1596557302360,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "OjToROni-7o5"
   },
   "outputs": [],
   "source": [
    "# Weights and biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3579a065997cae41f7f504916b6bc07878ac768c",
    "colab_type": "text",
    "id": "8qNNejI9-7pH"
   },
   "source": [
    "The *model* is simply a function that performs a matrix multiplication of the input `x` and the weights `w` (transposed) and adds the bias `b` (replicated for each observation).\n",
    "\n",
    "$$\n",
    "\\hspace{2.5cm} X \\hspace{1.1cm} \\times \\hspace{1.2cm} W^T \\hspace{1.2cm}  + \\hspace{1cm} b \\hspace{2cm}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left[ \\begin{array}{cc}\n",
    "73 & 67 & 43 \\\\\n",
    "91 & 88 & 64 \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "69 & 96 & 70\n",
    "\\end{array} \\right]\n",
    "%\n",
    "\\times\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "w_{11} & w_{21} \\\\\n",
    "w_{12} & w_{22} \\\\\n",
    "w_{13} & w_{23}\n",
    "\\end{array} \\right]\n",
    "%\n",
    "+\n",
    "%\n",
    "\\left[ \\begin{array}{cc}\n",
    "b_{1} & b_{2} \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "b_{1} & b_{2} \\\\\n",
    "\\end{array} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "b1119f5ae9688a5f31dba438c7f78ca382deb7e3",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4075,
     "status": "ok",
     "timestamp": 1596557302364,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "5G_d0Ka--7pJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "mu = np.mean(inputs, 0)\n",
    "sigma = np.std(inputs, 0)\n",
    "#normalizing the input\n",
    "inputs = (inputs-mu) / sigma\n",
    "inputs = np.hstack((np.ones((targets.size,1)),inputs))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8e0a4644cb1c4ed68a3bcf67a8a156341ac7c853",
    "colab_type": "text",
    "id": "nT94e2ZK-7pb"
   },
   "source": [
    "The matrix obtained by passing the input data to the model is a set of predictions for the target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "b042a3cf8f16f4c4380cccbac9d0892719c24190",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4054,
     "status": "ok",
     "timestamp": 1596557302367,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "VUpnkKlO-7pd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25082446 0.94675294 0.18932038 0.17929141]]\n"
     ]
    }
   ],
   "source": [
    "rg = np.random.default_rng(12)\n",
    "w = rg.random((1, 4))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5551ef933de7902c8b5a38ae3d8e4795cb244f38",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4031,
     "status": "ok",
     "timestamp": 1596557302371,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "KuIPDbJV-7po"
   },
   "outputs": [],
   "source": [
    "# Compare with targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2c4a9cf2b3c9152f2f832176bce9a87381e2419c",
    "colab_type": "text",
    "id": "Q-NuYiwI-7p4"
   },
   "source": [
    "Because we've started with random weights and biases, the model does not perform a good job of predicting the target varaibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "edaae7266f5d47c5e970e1438a812f10d8d35fb4",
    "colab_type": "text",
    "id": "hiNOZ2g1-7p7"
   },
   "source": [
    "## Loss Function\n",
    "\n",
    "We can compare the predictions with the actual targets, using the following method: \n",
    "* Calculate the difference between the two matrices (`preds` and `targets`).\n",
    "* Square all elements of the difference matrix to remove negative values.\n",
    "* Calculate the average of the elements in the resulting matrix.\n",
    "\n",
    "The result is a single number, known as the **mean squared error** (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "dbf5bca8cbf2a3831089b454c70469e3748e9682",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4024,
     "status": "ok",
     "timestamp": 1596557302375,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "_wY9fW06-7p9"
   },
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return np.sum(diff * diff) / diff.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "90da6779aad81608c40cdca77c3c04b68a815c11",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4000,
     "status": "ok",
     "timestamp": 1596557302378,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "V__m5zOU-7qH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost before regression:  6961.124340607171\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "preds = model(inputs,w)\n",
    "cost_initial = mse(preds, targets)\n",
    "print(\"Cost before regression: \",cost_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x,w):\n",
    "    return x @ w.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ab3acadf389f30430b55c26c7979dcffaa974a5",
    "colab_type": "text",
    "id": "j-TOY_7g-7qS"
   },
   "source": [
    "The resulting number is called the **loss**, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c61acf9c3cff205d769fc52ed3b1b76f5ae66233",
    "colab_type": "text",
    "id": "kbQQKg0_-7qU"
   },
   "source": [
    "## Compute Gradients\n",
    "\n",
    "With PyTorch, we can automatically compute the gradient or derivative of the `loss` w.r.t. to the weights and biases, because they have `requires_grad` set to `True`.\n",
    "\n",
    "More on autograd:  https://pytorch.org/docs/stable/autograd.html#module-torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ef66710c6ef1944567c4dc033e1ca316f35490ab",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3991,
     "status": "ok",
     "timestamp": 1596557302380,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "jMUIxzeO-7qW"
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "def gradient_descent(X, y, w, learning_rate, n_iters):\n",
    "    J_history = np.zeros((n_iters,1))\n",
    "    for i in range(n_iters):\n",
    "        h = model(X,w)\n",
    "        diff = h - y\n",
    "        delta = (learning_rate/targets.size)*(X.T@diff)\n",
    "        new_w = w - delta.T\n",
    "        w=new_w\n",
    "        J_history[i] = mse(h, y)\n",
    "    return (J_history, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6504cddcfb4bfb0817bf03ef460f08f3145a9091",
    "colab_type": "text",
    "id": "CtacVbsp-7qk"
   },
   "source": [
    "The gradients are stored in the `.grad` property of the respective tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5943d1cef604a178c95f5e8d255519d42d9f9982",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3966,
     "status": "ok",
     "timestamp": 1596557302382,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "RWG8jqkG-7qo"
   },
   "outputs": [],
   "source": [
    "# Gradients for weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "47278e318b156c6a5812e0842dbc4164c8362562",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3944,
     "status": "ok",
     "timestamp": 1596557302384,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "SzeDazjr-7qx"
   },
   "outputs": [],
   "source": [
    "# Gradients for bias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "466dc3a2cc2d4bd2c10ae4cf59cf4627b5cc9c75",
    "colab_type": "text",
    "id": "6HohuU-I-7q_"
   },
   "source": [
    "A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases. \n",
    "\n",
    "* If a gradient element is **postive**, \n",
    "    * **increasing** the element's value slightly will **increase** the loss.\n",
    "    * **decreasing** the element's value slightly will **decrease** the loss.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* If a gradient element is **negative**,\n",
    "    * **increasing** the element's value slightly will **decrease** the loss.\n",
    "    * **decreasing** the element's value slightly will **increase** the loss.\n",
    "    \n",
    "\n",
    "\n",
    "The increase or decrease is proportional to the value of the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35ed968bfc135bd44eeb100ae401d0628fbc5c63",
    "colab_type": "text",
    "id": "oRgBMWgV-7rB"
   },
   "source": [
    "Finally, we'll reset the gradients to zero before moving forward, because PyTorch accumulates gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "5f02dc376c21857d4e545d98413952c5ac73039b",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3929,
     "status": "ok",
     "timestamp": 1596557302387,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "lwkeQev0-7rD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5501c66c9729c4954e9b798a0634a9d84487e639",
    "colab_type": "text",
    "id": "pjKbQIcT-7rN"
   },
   "source": [
    "## Adjust weights and biases using gradient descent\n",
    "\n",
    "We'll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps:\n",
    "\n",
    "1. Generate predictions\n",
    "2. Calculate the loss\n",
    "3. Compute gradients w.r.t the weights and biases\n",
    "4. Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "5. Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "ef0d2bd2d9c5acb60992e238439ee00c2223319f",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3913,
     "status": "ok",
     "timestamp": 1596557302390,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "NbJYF_oB-7rP"
   },
   "outputs": [],
   "source": [
    "# Generate predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "302ee8226da4ee5d0dad137c638573a79f8abded",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3896,
     "status": "ok",
     "timestamp": 1596557302392,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "yt9A0Bzw-7rb"
   },
   "outputs": [],
   "source": [
    "# Calculate the loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "01c596aecf87e4670033ddd4ed36e26b97e2f9ab",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3896,
     "status": "ok",
     "timestamp": 1596557302399,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "X3U2apNf-7rp"
   },
   "outputs": [],
   "source": [
    "# Compute gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ec1e2bdc8f91523e556fad55ee8c01eb5431ae24",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3895,
     "status": "ok",
     "timestamp": 1596557302405,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "Gi8Iw67j-7rz"
   },
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "1d61b6f61f49b19099d29d1be8ec5ae4967bbd51",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3878,
     "status": "ok",
     "timestamp": 1596557302408,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "sB17H1hr-7sD"
   },
   "outputs": [],
   "source": [
    "#print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6af10c29db7cb0d6e869b2c30966a34a48a011e2",
    "colab_type": "text",
    "id": "YbNSWsxh-7so"
   },
   "source": [
    "With the new weights and biases, the model should have a lower loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c542b5fe75d82454f34cac13cdcff8b48dd1945c",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3863,
     "status": "ok",
     "timestamp": 1596557302412,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "tzhhX8xh-7su"
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5201901695f3ea13d7fdd5d985da7e0761c541d0",
    "colab_type": "text",
    "id": "JvUhV8nQ-7s9"
   },
   "source": [
    "## Train for multiple epochs\n",
    "\n",
    "To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "9f5f0ffeee666b30c5828636359f0be6addbef7c",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3860,
     "status": "ok",
     "timestamp": 1596557302416,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "rX0ZllBO-7tJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial cost is:  6961.124340607171 \n",
      "\n",
      "Optimal parameters are: \n",
      " [[75.70097746 -4.33569711 23.97784973 10.64122441]] \n",
      "\n",
      "Final cost is:  [3.24336209]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_iters = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "initial_cost = mse(model(inputs,w),targets)\n",
    "\n",
    "print(\"Initial cost is: \", initial_cost, \"\\n\")\n",
    "\n",
    "(J_history, optimal_params) = gradient_descent(inputs, targets, w, learning_rate, n_iters)\n",
    "\n",
    "print(\"Optimal parameters are: \\n\", optimal_params, \"\\n\")\n",
    "\n",
    "print(\"Final cost is: \", J_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "c4820ca48b78f4dc242d80a9ec3ec6aca1aef671",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3842,
     "status": "ok",
     "timestamp": 1596557302418,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "ym2eslp8-7ta"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(J_history)), J_history, 'r')\n",
    "\n",
    "plt.title(\"Convergence Graph of Cost Function\")\n",
    "plt.xlabel(\"Number of Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "bbcd65fa7094cec187565e54c2107e683bea787b",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3825,
     "status": "ok",
     "timestamp": 1596557302418,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "l7z9q9g9-7to"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      " [[ 55.41796548]\n",
      " [ 83.39462719]\n",
      " [116.02114736]\n",
      " [ 20.94681904]\n",
      " [102.72432753]]\n",
      "Targets:\n",
      " [[ 56.]\n",
      " [ 81.]\n",
      " [119.]\n",
      " [ 22.]\n",
      " [103.]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate error\n",
    "preds = model(inputs,optimal_params)\n",
    "cost_final = mse(preds, targets)\n",
    "# Print predictions\n",
    "print(\"Prediction:\\n\",preds)\n",
    "# Comparing predicted with targets\n",
    "print(\"Targets:\\n\",targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "addec2c4eca8edfcae5544ea2cc717182c21d90f",
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3807,
     "status": "ok",
     "timestamp": 1596557302420,
     "user": {
      "displayName": "Prof. Hariom Pandya",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggt3sg6X_951s0boD3SSJvqRng4AQaC3MhTBtGQ9Q=s64",
      "userId": "16159546014304882594"
     },
     "user_tz": -330
    },
    "id": "tEjLn-IO-7ty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after linear regression:  3.2263504141825856\n",
      "Cost reduction percentage : 99.95365187782436 %\n"
     ]
    }
   ],
   "source": [
    "# Print targets\n",
    "print(\"Cost after linear regression: \",cost_final)\n",
    "print(\"Cost reduction percentage : {} %\".format(((cost_initial- cost_final)/cost_initial)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-linear-regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
